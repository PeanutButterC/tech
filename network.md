### 1. 常见状态码

#### 1xx 请求已被接受，需要继续处理

100 服务器通知客户端已经收到请求，要求客户端继续发送请求，如果客户端请求已经发送完，就忽略这个响应，服务器需要发送一个最终响应；

101 服务器根据客户端的请求切换协议

#### 2xx 请求已被服务器接收、理解

200 成功

201 请求成功，服务器创建了新的资源

202 服务器已接受请求，但尚未处理

203 服务器已成功处理请求，但返回的信息可能来自另一来源

204 服务器成功处理请求，但没有返回任何内容

#### 3xx 要完成请求，需要进一步操作

300（多种选择）针对请求，服务器可执行多种操作，服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择

**301（重定向，永久移动）**请求的内容已永久移动到新位置，对get或者head请求的响应，会自动将请求者转到新的位置。

**302（重定向，临时移动）**目标资源临时移动到了另一个 URI 上，由于重定向是临时发生的，所以客户端在之后的请求中还应该使用原本的 URI。

303 （查看其它位置）表示服务器要将浏览器重定向到另一个资源，这个资源的 URI 会被写在响应 Header 的 Location 字段

**304 （资源未更新）**提示客户端请求的资源未修改过，意味着可使用上一次的缓存

305（使用代理）请求者只能使用代理访问所请求的网页

307（临时重定向）307 的定义实际上和 302 是一致的，唯一的区别在于，307 状态码不允许浏览器将原本为 POST 的请求重定向到 GET 请求上。

#### 4xx 客户端请求发生错误

400（错误请求）服务器不理解请求的语法

**401（未授权）**请求需要身份验证，一般见于需要登录的资源

403（禁止）服务器拒绝请求

**404（未找到）**服务器没找到请求的资源

405（方法禁用） 禁用请求中指定的方法

408（请求超时） 服务器等候请求时发生超时

#### 5xx 服务器发生错误、异常

500（服务器内部错误）服务器错误

501（尚未实施） 服务器不具备完成请求的功能

502（错误网关） 服务器作为网关或代理，从上游服务器收到无效响应

503（服务不可用） 服务器目前无法使用（由于超载或停机维护）

504（网关超时） 服务器作为网关或代理，但是没有及时从上游服务器收到请求

505（HTTP 版本不受支持） 服务器不支持请求中所用的 HTTP 协议版本

### 2. 强缓存和协商缓存的区别

1. 如果浏览器命中强缓存，则不需要给服务器发请求，直接去缓存；如果浏览器命中协商缓存，则由服务器决定是否使用缓存，会发生客户端和服务器的一次通信；
2. 在Chrome中，使用强缓存的状态码是200（from cache）（虽然未发请求），而如果走协商缓存，状态码是304（not modified）；

### 3. 浏览器使用缓存的流程

![image.png](https://segmentfault.com/img/remote/1460000021661659)

每一次http请求，都会先判断一下是否能用缓存；

第一次请求后，浏览器缓存资源，再次请求时，会走下面的步骤

1. 浏览器获取上一次请求缓存下来的header信息，根据header中的Expires和Cache-Control等字段判断是否命中强缓存；
2. 如果没有命中强缓存，就会发送请求到服务器，带上 `IF-Modified-Since`或者`IF-None-Match`等header字段，它们的值分别是第一次请求返回的`Last-Modified`或者 `Etag`，交给服务器来判断是否能够使用缓存，如果可以使用缓存则返回304，且不会返回资源，否则会返回最新的资源，并带上缓存相关header；

### 4. 什么情况下会命中协商缓存

当浏览器中存在所请求资源的缓存，并且该缓存已过期时，就会触发协商缓存，客户端向服务器发送请求，携带`If-None-Match`或者`If-Modified-Since`，它们的值分别是`Etag`和`Last-Modified`，交给服务器判断是否使用缓存。

### 5. 如果一个文件有强缓存，服务器修改文件后，如何让客户端访问到修改后的文件

这个问题就是如何保证发版后客户端能及时更新。

我们一般会保证让index.html不是强缓存，可以通过Cache-Control的no-cache命令，使其每一次都使用协商缓存（也必须使用协商缓存），而资源文件可以是强缓存的。我们只需要让资源文件名在更新后的hash名不一样，就可以保证浏览器能够请求新的资源文件。不过最好的方式是使用非覆盖式发布，也就是让新旧资源都能够访问到，这样不论index.html里引入的资源名是新还是旧，都不会崩掉。

### 6. Etag的计算规则

nginx 中 etag由响应头的 Last-Modified` 与 `Content-Length 表示为十六进制组合而成。

虽然它不完美，但很高效

所以Etag变了，并不意味着文件内容一定变了。

### 7. 二进制传输和文本传输的区别

比如有一段数据：name: 'fan', age: 20

文本传输是可以从传输的数据看出其含义的，会把这一整段都传输；

如果是二进制传输，首先会约定一个协议，比如前10个字节表示name，后10个字节表示年龄，此时，可以只需20个字节把'fan'和20传输过去就行。二进制传输的关键就是需要提前商定一个协议。

### 8. http/2新特性

现在浏览器对同一个域名的 TCP 连接个数有限制，一般是 6 - 8 个

#### http/1的缺陷

1. TCP连接本身的性能瓶颈，比如三次握手建立连接以及慢启动导致的传输速率低；
2. 队头阻塞，TCP是字节流传输，必须保证TCP报文的接收顺序，一个报文丢失，会阻塞后面的报文交付给应用层；
3. 头部大且重复，每一个http/1请求都会有大量重复的header，并且header还很大，比如cookie、userAgent等；
4. 明文传输不安全，https解决了这个问题；
5. 不支持服务器推送，服务器推送就是只请求了index.html，但服务器会把index.html、main.js、index.css三个文件一起响应给客户端，http/1只能一个一个地发请求；

#### http/2的优势

1. 二进制传输，按照提前商定的协议，http/2可以把传输的信息分割为更小的帧，数据分帧后，heade+body的结构就消失了，变成了一个个“碎片”；
2. header压缩，header会通过gzip或compress压缩后再发送，并且客户端和服务器还会维持一张表，所有header字段都会存入这个表，以后就不发送同样的字段了，只发索引号；
3. 多路复用，多路复用就是一个TCP连接下可以同时发多个请求，这样就不需要等到上一个请求的响应后再发下一个请求，
4. 服务端推送，允许未经客户端请求，主动向客户端发送资源，客户端可以选择是否接收

### http/1的keep-Alive长连接和http/2的多路复用的区别

1. http/1基于本文传输，http/2基于二进制传输，可分解为独立的帧，交错发送；
2. http/1只能一个一个按顺序响应，http/2不按序响应；
3. http/1单个TCP下一次只能处理一个请求，http/2同一时刻可发送多个请求；
4. http/1为了解决队头阻塞，会把同一页面的资源分散到不同域名下，建立多个TCP连接，http/2同域名下都在单个连接上完成；

### http/2缺陷

1. 建立TCP连接时间长；

2. http/2虽然解决了应用层的队头阻塞（不需要等待上一个请求收到响应才发送下一个请求），但TCP层面的队头阻塞是无法解决的，TCP连接里如果出现丢包，会停止，等待重传丢失的TCP包，此时后续的包是完全阻塞住的，会被放在缓存区，但不会交给应用层。并且万一丢包，http2比http1.0在TCP层面的队头阻塞会更加严重，因为http2是单TCP连接，流量非常大，丢包后阻塞的更多，而http1.0下会开多个TCP连接，一个出问题还能保证其它的正常。

### 为什么http/1.x不能实现多路复用

http/1.x只允许串行发送http请求，收到上一个请求的响应后才能发送下一个请求，也就是多个请求不能重叠；

http/1.x有了管道机制之后，可以允许在一个TCP连接里并行多个http请求（不用等待上一个请求返回就可以发送下一个请求），但是由于http/1.x使用的是文本协议，服务端在应用层接收消息的时候，是以分隔符来判断的，因此，只能把一个http请求全部接收后，才能接收下一个http请求，所以虽然可以并行发请求了，但实际上还是必须按发送请求的顺序进行接收和响应；

确实可以：http/2有二进制分帧这个步骤，会把请求消息分割成帧，帧有自己的结构，服务器的应用层拿到的就是多个请求大量的帧，不过，因为每个帧都标记了它属于哪个请求，因此可以完整地把收到的帧分属到不同的请求，这样就不存在必须将一个请求全部解析完成后才能解析下一个请求的问题，一个TCP连接中，可以并行多个请求，并且可以不按发送顺序来响应，谁先解析完就先响应；

### 简述TCP连接三次握手

SYN：是TCP报文的一个标志位，为1则表示请求建立连接；

ACK：是TCP报文的一个标志位，为1则表示这是一个确认报文；

TCP报文中有序列号位和确认应答号位，都有32位，seq就是序列号

前提：客户端和服务端都处于CLOSE状态，随后服务端监听端口（进入LISTEN状态）

1. 客户端发送SYN报文，请求建立TCP连接，并携带自己的序列号seq = x，进入SYN-SENT状态
2. 服务端收到SYN报文后，发送SYN + ACK报文，并携带自己的序列号seq = y，进入SYN-RECE状态；
3. 客户端收到服务端发来的确认报文后，发送SYN+ACK报文，进入ESTABLISH状态，可携带数据；
4. 服务端收到确认报文后，也进入ESTABLISH状态

### 第三次握手时可以携带数据吗

可以，当客户端收到服务端的确认报文后，表示服务器具备接收和发送数据的能力，于是就可以在第三个报文中带上数据

### 为什么是三次握手，而不是两次？

1. 阻止历史连接的建立（主要原因），如果客户端发出第一个SYN后宕机，且这条旧的SYN阻塞了，重启机器后再发送第二个SYN，导致客户端先接收到旧的ACK；如果是两次握手，那么服务器会认为第一个TCP连接请求建立成功，可以发送数据，但此时客户端根本就没有这条连接了；如果是三次握手，客户端收到旧ACK发现其“确认序列号”并不是确认第二次发出的SYN的，就会将其销毁，继续等待确认报文，这就销毁了旧的TCP连接被建立的可能。
2. TCP的本质是要保证可靠连接，实现的核心之一就是序列号，三次握手可以同步两端的序列号；
3. 防止资源浪费，如果客户端发送SYN后收不到ACK（ACK被阻塞），就会重新发送SYN，但此如果是两次握手的话，服务端会进入ESTABLISH状态，如果老是收不到ACK，就会导致服务端建立多个TCP连接而浪费资源。

### 为什么是三次握手，而不是四次？

三次握手实际是因为第二个报文合并了ACK报文和服务端SYN报文，它们本来是两个报文。

### 为什么建立TCP连接时，初始的序列号都不一样

那客户端和服务端就分不清TCP报文是属于哪一个连接的了（谁是谁的）

### 什么是半连接队列和全连接队列

TCP三次握手的时候，Linux会维护两个队列，它们都有最大长度限制，分别是：

- 半连接队列，服务端收到SYN并发出ACK后，就把该连接存储到半连接队列
- 全连接队列，服务端收到客户端发来的ACK后，就把该连接从半连接队列中取出来，创建新的完全连接，放进全连接队列

### 简述SYN攻击

SYN攻击就是在三次握手阶段，用不同的IP地址向服务端发送大量SYN报文，收到服务端的SYN+ACK后，却不发ACK报文，让大量的连接处于SYN-RECE状态，这样把服务端的半连接队列打满，服务端再收到SYN请求连接时，就会因为队列已满而丢弃新发来的SYN报文，无法再建立TCP连接。

### 有什么办法解决SYN攻击

- 增大半连接队列的长度；
- 减少SYN+ACK报文重传的次数，当大量的连接处于SYN-RECE状态而收不到确认报文时，会不停地重传，可以减少最大重传次数，让服务端更快地停止建立连接流程；
- 开启tcp_syncookies，可以不使用半连接队列就建立TCP连接；

### 简述TCP四次挥手

任意一方都可以发起断开TCP连接。

1. 客户端发送FIN报文，进入FIN-WAIT-1状态
2. 服务端收到后发送ACK报文，进入CLOSE-WAIT状态
3. 客户端收到ACK报文后，进入FIN-WAIT-2状态
4. 服务端把数据发送完毕后，再发一条FIN报文，进入LAST-ACK状态
5. 客户端收到FIN报文后，发送ACK报文，进入TIME-WAIT状态，2msl

### 为什么客户端发送完最后一个ACK报文后，要等待2msl才能断开连接

这是因为防止最后一个ACK报文被阻塞，没有到达服务端，而导致服务端重发FIN报文，重发的FIN必然会在2msl之内到达客户端，这样客户端可重新计时TIME-WAIT。

1msl表示一个TCP报文在网络中最多存在的时间。

### 为什么是四次挥手

当服务端收到FIN报文后，会先发送一个ACK，但此时可能还有数据没有传送完毕，因此还不能断开连接，等到数据全部传送完毕后，再发送FIN，表示此时可以断开连接了。

### ACK报文可以重传吗？

不可以，如果第二次挥手客户端没有收到ACK报文，服务端并不会重传ACK，而只能是客户端重传FIN，发起断开连接。

### 跨域解决方案有哪些，简述它们

- CORS（Cross-Origin-Resource-Sharing）

  CORS需要服务器和浏览器同时支持，而浏览器大部分已经支持，开发人员的Ajax代码没有变，还是正常发请求，当浏览器发现请求的是一个不同源的资源时，会自动加上一些头部，可能还会有多次请求，但用户无法感知到。因此实现CORS跨域的关键就是服务器要实现CORS接口。

  CORS跨域中的请求有两种：简单请求和非简单请求，如何分类的看[这里](https://www.ruanyifeng.com/blog/2016/04/cors.html)。

  对于简单请求，一旦浏览器发现跨院请求是一个简单请求，就在头部加上Origin头，值是协议+域名+端口，表示请求来自哪个源，服务器收到后根据这个值是否同意请求。一旦同意，在响应头部中就会添加`Access-Control-Allow-Origin`等，浏览器如果发现响应头部中的`Access-Control-Allow-Origin`中含有请求头部的`Origin`，就接收它，否则用户无法得到该响应。

  对于非简单请求，在正式发送请求报文前，先发一个预检请求，询问服务器是否同意这个跨域请求，服务器一旦同意，浏览求才会发送真正的Ajax请求。

  之所以要区分简单和非简单请求，就是因为一般简单请求都是获取资源的请求，不会对服务器造成损害，体积也小，服务器可以放心把资源发回来，留给浏览器决定是否展示，但非简单请求一般都是会对服务器有影响的操作，而且数据量一般比较大，服务器必须先确定是否允许它们发过来，同时也可以减少网络通信量，于是就得先有预检请求。

- JSONP（Json with Padding）

  注意到script标签、iframe等标签中的src发送请求时，浏览器是不会管它是否同源的，会直接发送请求。于是我呢们就可以使用script标签发送请求，而服务器不再返回json数据，而是返回一个调用某个函数的代码，这个函数需要在前端提前定义。示例代码：

```javascript
let btn = document.querySelector('.btn');
function showJsonp(obj) {
    console.log(obj.message);
}
btn.addEventListener('click', () => {
    let url = 'http://localhost:3000/jsonp?func=showJsonp';
    let script = document.createElement('script');
    script.setAttribute('src', url);
    script.setAttribute('type', 'text/javascript');
    document.body.appendChild(script);
});
```

#### HTTPS和HTTP的区别

1. HTTP协议用明文方式发送内容，数据都是未加密的，安全性差。HTTPS数据传输过程是加密的。
2. HTTPS需要到数字证书认证机构（Certificate Authority, CA）申请证书。
3. HTTP和HTTPS采用的是完全不同的连接方式，默认端口也不一样。
4. HTTP页面响应比HTTPS快，主要是因为HTTP采用3次握手建立连接，而HTTPS除了TCP的三次握手外，还需要经历TLS协商过程。

### https用到了哪些加密技术？

1. 非对称加密算法RSA
2. 对称加密
3. 数字证书、数字签名
4. hash算法

### 什么是MAC地址？它在哪一层？它有什么用？

MAC地址是标识网络设备位置的地址，即每个网卡都有一个自己的MAC地址，并且这个MAC地址是唯一的，在实际的网络链路中传递数据帧只能用MAC地址。

MAC地址属于数据链路层。

在数据链路层，每一个交换机中都维护着一张表，表中每一项都是一个MAC地址和接口，表示该MAC地址对应的设备接在交换机的哪个接口上，交换机就是通过这张表来确定应该把数据送到哪个接口，最终送到对应设备的。

在交换机上会用ARP协议来将IP地址解析为MAC地址，然后再找MAC地址对应的接口，并把数据从这个接口发出去。

但不可能把全世界所有的设备都接到一个交换机上，那就需要路由器了，路由器中维护的是ip地址，设备的ip地址是可以变的，数据会根据ip地址传送到离设备最近的路由器上，再由路由器转发给交换机，最后让交换机决定发到哪台设备上。

所以总结下来MAC地址的作用就是为了让交换机最终能够找到拥有该MAC地址的设备。

### HTTP是无状态协议，如何保存用户状态

1. 基于Session实现的会话保持

   在客户端第一次向服务器发送HTTP请求后，服务器会创建一个session对象，并将客户端的身份信息以键值对的形式存储下来，然后分配一个会话标识（Session ID）给客户端，这个Session ID一般保存在客户端的cookie中，之后客户端每次发送HTTP请求到该服务器，都会带上Session ID，服务器根据该标识就可以将之前的状态信息与会话联系起来，从而实现会话保持。

   优点：安全性高，状态信息保存在服务器端，**为什么安全性高**，因为我们通常发送Cookie时，Set-Cookie头部会包含用户的信息，比如`Set-Cookie: userName=fan`，而在浏览器这个cookie是可以被查看和修改的，所以不安全，那就不要把身份信息写在cookie里，直接使用SessionId，它是一个随机码，可用`Set-Cookie: sessionid=25`，然后通过cookie中的sessionId，找到存在服务器内的session，用户和状态信息就都在里面了，不会泄露。

   缺点：由于大型网站往往采用的分布式的服务器，客户端发送的HTTP请求需要经过负载均衡器才能到达具体的后台服务器，如果两次HTTP请求分别落在不同的服务器上，基于Session的方法就不能实现状态保持了，因为状态信息存储在前一台服务器中。解决方案就是使用中间件，如Redis，使每个服务器都能访问存储在Redis中的Session对象。

### 什么是token（json web token）

### https整个过程需要多少RTT（Round Trip Time）

1. 建立TCP连接三次握手（1.5 RTT）
2. 建立TLS连接四次握手（2 RTT，是最长的消耗）
   - 客户端发送自己支持的加密算法等给服务端
   - 服务端确定加密算法并把证书等返回给客户端
   - 客户端验证证书后把私钥加密传送给服务端
   - 服务端发送确认报文
3. 发送http请求并收到响应两次交互（1 RTT）

所以包含http请求的话，一共是4.5 RTT，

### 优化TLS握手的方法

1. 建立TLS连接需要四次握手（2 RTT），以前都是使用RSA密钥交换算法，即用非对称密钥保护对称密钥，可以不用RSA，改用ECDHE算法，它的特点是不用等待服务端发起的第四次握手，可提前发出加密的HTTP数据，把时间缩短为1 RTT（一、二次握手耗时）；
2. 证书传输优化，就是减小证书的大小，即选择其它类型的证书；
3. 证书验证优化，因为浏览器为了验证证书是否被CA吊销，还会再访问CA，获取证书吊销列表，但每次都访问CA会很浪费时间，因此可以让浏览器周期性地访问CA，定期同步证书吊销列表；
4. 升级TLS1.2到TLS1.3，它就是支持ECDHE密钥交换算法的。

### RSA密钥交换算法和ECDHE密钥交换算法的区别

最主要的区别就是，使用RSA，需要等待TLS完成四次握手后，才能发送http数据，而ECDHE不用等第四次握手就可以发送http数据；

### TCP和UDP的区别

1. 连接，TCP面向连接，UDP 不需要连接，即刻传输数据；
2. 可靠性，TCP可靠，UDP 是尽最大努力交付，不保证可靠交付数据；
3. 传输方式，TCP传输是字节流，没有边界但保证顺序可靠，而UDP是数据报，有边界，边界就是单个UDP报文；
4. 拥塞控制和流量控制机制，UDP没有，即使网络拥堵，也照样发送；
5. 分片不同，TCP超过MSS会在传输层将数据分片，UDP报文超过MTU会在IP层分片；

### MSL、RTT、MSS、MTU分别是什么

MSL（Maximum Segment Lifetime）TCP报文在网络中的最大生存时间

RTT（Round Trip Time）往返时间

MSS（Maximum Segment Size）TCP报文段中数据部分的最大字节数

MTU（Maximum Transfer Unit）最大传输单元，当UDP报文长度超过MTU就会在IP层分片

### DNS

首先是一个由有层次的DNS服务器实现的分布式数据库，其次是一个使得主机能够查询分布式数据库的应用层协议。DNS协议运行在UDP上，使用53号端口。DNS服务器通常是运行BIND软件的UNIX机器。

作用：浏览器解析出主机名，交给DNS客户端，DNS客户端向DNS服务器发送请求获取主机名对应的IP地址，收到后发回给浏览器，浏览器用该IP地址发送HTTP请求。具体作用如下：

1. 将主机名转换为IP地址；
2. 将主机别名转换为规范主机名或IP地址；
3. 将邮件服务器别名转换为规范主机名或IP地址；
4. 负载分配，同一个主机名可能对应多个IP地址，服务会部署在多台服务器上，当向DNS服务器请求主机名到IP地址的转换时了，DNS服务器会响应IP地址集合（轮流排序），而客户端会取第一个IP地址发送请求，从而实现负载分配，防止所有请求都交给一台服务器造成压力过大。

DNS服务器是有层次的，分为

1. 根DNS服务器；
2. 顶级域DNS服务器；
3. 权威DNS服务器（比如NYC有自己的DNS服务器，负责存储各个系自己的服务器）。
4. 本地DNS服务器（严格来说不属于该层次结构，但它至关重要）

DNS的查询过程示例（迭代）：

1. 本地主机向本地DNS服务器发送DNS请求；
2. 本地DNS服务器将请求发送给根DNS服务器，随后返回顶级域DNS服务器IP地址；
3. 本地DNS服务器发送DNS请求给顶级域DNS服务器，随后返回权威DNS服务器IP地址；
4. 本地DNS服务器收到后将DNS请求发送给权威DNS服务器，权威DNS服务器返回确切主机的IP地址；
5. 本地DNS收到该确切IP地址后，返回给主机。

### 逐级解析`www.bytedance.com`的过程

`.com`是顶级域名，`.bytedance`是一级域名，`www`是二级域名，`www`只是提供公司众多服务中的一种服务子域名

1. 浏览器把该域名交给本地DNS服务器；
2. 本地DNS服务器向根DNS服务器请求，发现顶级域名是.com，于是返回.com顶级域DNS服务器；
3. 本地DNS服务器向顶级域DNS服务器请求，发现一级域名是`bytedance.com`，返回bytedance的权威DNS服务器；
4. 本地DNS服务器向权威DNS服务器请求，发现二级域名是`www.bytedance.com`，就把对应的ip地址返回；
5. 本地DNS服务器将结果返回给浏览器；

### CLOSE-WAIT和TIME-WAIT的状态和意义

CLOSE-WAIT是Server第一次告知Client，自己已经收到释放请求后，进入的状态，在此状态，Server会发送一些遗留的数据，发送完后，会再发一条FIN报文，告诉Client自己已经准备好释放了。

TIME-WAIT是Client收到Server发来的已准备释放报文后进入的状态，也就是，缓一缓再断开，以防有特殊情况发生，比如：如果Client收到Server准备释放的报文后，发出ACK报文，并立刻断开连接，但这条ACK报文丢失了，那么Server发现很久收不到确认报文，过一段时间则会重传，但此时Client那一端已经断开了该TCP连接，则会发送RST报文，Server会认为出现了异常，但实际是正常的。又或者Client断开后立马用该端口创建新的进程，有可能新进程会受到Server发给上一个进程的一些遗留的数据，造成异常。

### TCP粘包是什么，怎么解决

由于TCP是面向字节流的，如果要发送两条用户消息，这两条用户消息可能会被封在同一个TCP报文中，这就是粘包；如果一条用户消息太大被拆分封在两个TCP报文中，这就是拆包。也有可能粘包和拆包同时发生。

解决方案：

1. 将用户消息的长度固定，这样应用层就以固定的长度为分界点；
2. 特殊字符作为边界，在两条用户消息之间，用特殊字符划分开；
3. 自定义结构，可以把用户消息定义成头+数据两部分，头中存放着数据的长度；

### TCP流量控制与拥塞控制

流量控制，就是让发送方的发送速率不要太快，让接收方来的及接收，如果接收方来不及接收发送方的数据，就会有分组丢失，利用可变长的滑动窗口机制可以很方便地实现对发送方的流量控制。主要的方式是接收方返回的ACK报文中包含自己的**接收窗口大小**。

拥塞控制，防止过多的数据注入网络，避免负载过大的情况，常用的解决办法有**：慢开始和拥塞避免、快恢复**。

流量控制和拥塞控制的区别：拥塞控制往往是全局的，防止过多数据注入网络中，只要发送方收不到对方的确认信息，猜想网络中发生了拥塞，但并不知道拥塞在何处。流量控制往往指**点对点**通信量的控制，是端到端的问题。

### 视频面试用到了哪些协议

https、http、DNS、TCP、UDP（DNS请求）、ARP（地址解析）等

### CSRF攻击原理

一句话：服务器误把黑客发送的请求当成是自己网站发送的请求了。

用户先在在网站A登录，浏览器会保存对应的cookie，随后用户又打开一个tab，访问了B钓鱼网站，B网站中会发起对网站A的请求，请求会被浏览器自动带上cookie，导致和正常的权限一样。（为什么会存在csrf呢，因为这是很老的攻击方式，当时还没有Origin header，xhr2才带上origin）。

防御手段

1. 就是使用Origin和Referer 这两个header，这个头是浏览器自动加的，可以让后端判断这个字段来决定是否禁止。
2. 使用token，让用户的每一次请求都携带上这个token，由于这个token都是图片验证码这种形式，黑客根本没办法拿到，因此服务器就可以根据这个验证码是否正确来判断该请求是不是自己的网站发起的。

### xss攻击原理

用户先登录网站，再点击钓鱼链接，攻击者向网站中插入恶意的脚本，当用户加载了这些脚本，就会执行恶意操作，比如自动发朋友圈等。

插入恶意脚本的方式可以是攻击者将url中拼上恶意的查询参数（脚本），服务器收到后会把查询参数展示在网页上（插入在DOM中），导致脚本被执行。

比如攻击者在输入框中输入恶意脚本并发布，其他用户只要加载了这些内容，就会执行恶意脚本。

### TCP滑动窗口是干什么的，原理？

TCP每一个报文发出去之后，都会有确认应答报文回来，然后才能发送下一个报文，但这样效率极低。

于是就可以在发送方维护一个滑动窗口，每一个已发送但未收到确认应答的TCP报文都要放在这个缓冲区中等待确认应答，这样效率大大提高。比如滑动窗口大小是10，一次性最多就可以发10个TCP报文，收到一条确认应答，就把它从缓冲区移除，滑动窗口维护三个指针。

### 什么是流量控制？

TCP报文不能无脑发送，要考虑接收方的接收能力，因此需要在接收端维护一个滑动窗口，每一个ACK报文向发送方汇报自己的接收窗口有多大，从而实现流量控制。

### 窗口关闭问题？

接收方接收窗口从0变成非0，空出来之后，向发送方发送自己的窗口大小，如果这个ACK报文丢失，就会导致发送方不发送报文、接收方也接收不到报文，造成死锁。

为了解决这个问题，发送方会在接收到0窗口报文后，启动持续计时器，计时器超时，就会发送窗口探测报文，打破死锁局面。

### 拥塞控制如何实现？

维护一个拥塞窗口，当网络状态变好， 拥塞窗口就会变大，网络差，拥塞窗口就会缩小。

TCP如何判断网络拥塞的？其实就是ACK报文是否能按时收到

#### 慢启动

TCP连接建立后，先发少量TCP报文，每收到一个ACK，拥塞窗口就加1，随后慢慢增加发送的速率（扩大拥塞窗口），这是指数级增长（2的n次方）

#### 拥塞避免

当拥塞窗口的大小由慢启动增长到一定的门限后，就进入拥塞避免算法，原来的指数增长会变为线性增长。

#### 拥塞发生

拥塞窗口不断增长，最后网络就开始拥堵，就会触发拥塞发生，主要有两种方式触发：

1. 超时重传，拥塞窗口就会急剧减小，拥塞避免的门限也会减小，然后再慢启动。
2. 快速重传，接收方发现丢包后，连发三次前一个包的ACK报文，发送端就会立刻重传，不必等到超时重传，TCP认为这种情况不严重，只是丢了一个包，网络状况还不错，就不会急剧减小拥塞窗口大小和门限。

#### 快速恢复

快速重传之后，就进入快速恢复算法，不像超时重传触发拥塞发生那样，一炮回到解放前，拥塞窗口还维持在高位，继续呈线性增长。

### 网络层有哪些协议

1. IP

2. 地址解析协议（ARP）

   用于将IP地址解析为MAC地址的协议，每台主机都有ARP高速缓存，维护着IP地址和对应MAC地址

3. ICMP协议，用于传送数据传输相关的错误信息

4. IGMP协议，用来在接收者主机和直接相邻的组播路由器之间**建立和维护**组播组成员的关系

### 各层有哪些协议

应用层：HTTP、FTP、SMTP、DNS、（TLS）

传输层：TCP、UDP

网络层：IP、ICMP、IGMP、ARP（地址解析协议）

数据链路层：PPP（在两节点间建立直接的连接）

物理层：蓝牙连接协议

### websocket和socket的区别

Socket就是网络中进程间通信的端点，Socket是一个东西，表示为（IP地址:端口号），这个东西后面连接应用进程，前面负责收发网络数据。通俗讲它就好像是公司前台，后面是运作着的公司，前面负责处理外务。

websocket是应用层协议，不同于http，实现了服务器也可以主动向客户端推送消息，基于TCP。
